{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1xbtws4ClcVrnFu8iRu06Zk7TTIju--l7",
      "authorship_tag": "ABX9TyN64PmRPTg2txx4gYRw29KK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neha-5456/Data-Anylasis-/blob/main/data_anyalsis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_aDVl3gMpO1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data =  pd.read_csv('/content/drive/MyDrive/ml/MagicBricks.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Lrl1AjhQNTKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['Parking','Transaction','Type' ], inplace= True )\n",
        "data.head()"
      ],
      "metadata": {
        "id": "CssDfKd6Nllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "P80C-bIbOCAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Furnishing'].value_counts()"
      ],
      "metadata": {
        "id": "1fRgCKA6Qb4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Furnishing'] = data['Furnishing'].fillna('Semi-Furnished')"
      ],
      "metadata": {
        "id": "UKt1AhzaRVkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Bathroom'] = data['Bathroom'].fillna(2)  # Note: numeric 2, not string '2'"
      ],
      "metadata": {
        "id": "mGJ8ma5RReHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['Per_Sqft'] = data['Per_Sqft'].fillna(data['Per_Sqft'].median())"
      ],
      "metadata": {
        "id": "GF7ANXQpTC4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Per_Sqft'] = data['Per_Sqft'].astype(float)\n",
        "mask =  data['Per_Sqft'].isna() & data['Area'].notna() & (data['Area'] != 0)\n",
        "# Price Per Sq Ft = Total Price / Area\n",
        "data.loc[mask, 'Per_Sqft'] = data.loc[mask, 'Price'] / data.loc[mask, 'Area']\n",
        "group_means = data.groupby(['Locality', 'BHK'])['Per_Sqft'].mean()\n",
        "data['Per_Sqft'] = data.apply(\n",
        "    lambda row: group_means.get((row['Locality'], row['BHK']), row['Per_Sqft'])\n",
        "    if pd.isna(row['Per_Sqft'])\n",
        "    else row['Per_Sqft'],\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "rVLfjRGkT7n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "MP8rtoGqUh7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Per_Sqft'].describe()"
      ],
      "metadata": {
        "id": "fpvysar5UlkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import seaborn as sns\n",
        "sns.boxplot(data=data, y='Per_Sqft')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "8rMicMAk4Wpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X = data.drop('Price', axis=1)\n",
        "# y = data['Price']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2, random_state=42\n",
        "# )"
      ],
      "metadata": {
        "id": "MBFzngWrVEyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# # Define numeric and categorical features\n",
        "# numeric_features = ['Area', 'BHK', 'Bathroom', 'Per_Sqft']\n",
        "# categorical_features = ['Locality', 'Furnishing', 'Status']\n",
        "\n",
        "# # Create transformers\n",
        "# numeric_transformer = Pipeline(steps=[\n",
        "#     ('scaler', StandardScaler())\n",
        "# ])\n",
        "\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "\n",
        "# # Combine transformers\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numeric_transformer, numeric_features),\n",
        "#         ('cat', categorical_transformer, categorical_features)\n",
        "#     ])"
      ],
      "metadata": {
        "id": "6O8L5laAVJM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# # Create pipeline\n",
        "# model = Pipeline(steps=[\n",
        "#     ('preprocessor', preprocessor),\n",
        "#     ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "# ])\n",
        "\n",
        "# # Train model\n",
        "# model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "V0rcx9NWVSt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# # Predictions\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Evaluation metrics\n",
        "# print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
        "# print(f\"R2 Score: {r2_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "id": "v4lhK1teVWTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}